const OpenAI = require("openai");
const dotenv = require("dotenv");

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ í•„ìš”)
dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY // .env íŒŒì¼ì— API í‚¤ ì €ì¥ í•„ìš”
});

async function askOpenAI(prompt) {
  try {
    // í”„ë¡¬í”„íŠ¸ ì •ì˜

    if(!prompt)
      return;

    const finalPrompt = `
    ì´ ìŒì„± í…ìŠ¤íŠ¸ëŠ” íšŒì˜ ì¤‘ ê¸°ë¡ëœ ëŒ€í™”ì…ë‹ˆë‹¤. ë˜í•œ ì•„ë˜ì˜ ë§ˆì¸ë“œë§µ ë…¸ë“œëŠ” íšŒì˜ ì¤‘ ì‘ì„±ëœ ë…¸ë“œì…ë‹ˆë‹¤.

    ### ğŸ“ **ëª©í‘œ**
    - **ìŒì„± í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ íšŒì˜ì˜ ëª©ì ì„ íŒŒì•…**í•˜ì„¸ìš”.
   

    ### ğŸ” **ì…ë ¥ ë°ì´í„°**
    #### **ìŒì„± í…ìŠ¤íŠ¸**
    ${prompt}

  
    ---

    ### **ğŸ“Œ ì‘ì—… ë‚´ìš©**
    1. **ìŒì„± í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•œ SRT íŒŒì¼ì„ ë°˜í™˜í•˜ì„¸ìš”.**
    2. **SRT íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ íšŒì˜ë¡ì„ ì‘ì„±í•˜ì„¸ìš”:**
      - **íšŒì˜ ëª©ì **
      - **ì£¼ìš” ì£¼ì œ**
      - **ë‹¤ìŒ í•  ì¼**
      - **ìš”ì•½**
      - **í‚¤ì›Œë“œ**
  

    ---

    ### **ğŸ“Œ ì‘ë‹µ í˜•ì‹**
    \`\`\`json
    {
      "srt": "<SRT ë‚´ìš©>",

      "minutes": {
        "íšŒì˜ ëª©ì ": "[íšŒì˜ì˜ í•µì‹¬ ëª©ì ]",
        "ì£¼ìš” ì£¼ì œ": [
          "[ë‚´ìš©]"
        ],
        "ë‹¤ìŒ í•  ì¼": [
          "[ë‚´ìš©]"
        ],
        "ìš”ì•½": "[ê°„ë‹¨í•œ ìš”ì•½ ë‚´ìš©]",
        "í‚¤ì›Œë“œ": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]
      },
    }
    \`\`\`
    `;


    const response = await openai.chat.completions.create({
      model: "gpt-4", // ë˜ëŠ” "gpt-3.5-turbo"
      messages: [{ role: "user", content: finalPrompt }],
      max_tokens: 1000,
    });

    console.log("OpenAI ì‘ë‹µ:", response.choices[0].message.content);

    return response;
  } catch (error) {
    console.error("ì˜¤ë¥˜ ë°œìƒ:", error);
  }
}

module.exports = { askOpenAI };


